{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\ud83d\ude34 Turbulette, a batteries-included framework to build high performance, async GraphQL APIs \ud83d\ude34 Turbulette packages all you need to build great GraphQL APIs : ASGI framework, GraphQL library, ORM and data validation Features : Split your API in small, independent applications Generate Pydantic models from GraphQL types JWT authentication with refresh and fresh tokens Declarative, powerful and extendable policy-based access control (PBAC) Extendable auth user model with role management Async caching (provided by async-caches) Built-in CLI to manage project, apps, and DB migrations Built-in pytest plugin to quickly test your resolvers Settings management at project and app-level (thanks to simple-settings) CSRF middleware 100% test coverage 100% typed, your IDE will thank you ;) Handcrafted with \u2764\ufe0f, from \ud83c\udde8\ud83c\uddf5 Requirements Python 3.6+ \ud83d\udc4d Turbulette makes use of great tools/frameworks and wouldn't exist without them : Ariadne - Schema-first GraphQL library Starlette - The little ASGI framework that shines GINO - Lightweight, async ORM Pydantic - Powerful data validation with type annotations Alembic - Lightweight database migration tool simple-settings - A generic settings system inspired by Django's one async-caches - Async caching library Click - A \"Command Line Interface Creation Kit\" Installation pip install turbulette You will also need an ASGI server, such as uvicorn : pip install uvicorn \ud83d\ude80 Quick Start Here is a short example that demonstrates a minimal project setup. We will see how to scaffold a simple Turbulette project, create a Turbulette application, and write some GraphQL schema/resolver. It's advisable to start the project in a virtualenv to isolate your dependencies. Here we will be using poetry : poetry init Then, install Turbulette from PyPI : poetry add turbulette For the rest of the tutorial, we will assume that commands will be executed under the virtualenv. You can either prepend all commands with poetry run , or spawn a shell inside the virtualenv : poetry shell 1: Create a project First, create a directory that will contain the whole project. Now, inside this folder, create your Turbulette project using the turb CLI : turb project eshop You should get with something like this : . \u2514\u2500\u2500 \ud83d\udcc1 eshop \u251c\u2500\u2500 \ud83d\udcc1 alembic \u2502 \u251c\u2500\u2500 \ud83d\udcc4 env.py \u2502 \u2514\u2500\u2500 \ud83d\udcc4 script.py.mako \u251c\u2500\u2500 \ud83d\udcc4 .env \u251c\u2500\u2500 \ud83d\udcc4 alembic.ini \u251c\u2500\u2500 \ud83d\udcc4 app.py \u2514\u2500\u2500 \ud83d\udcc4 settings.py Let's break down the structure : \ud83d\udcc1 eshop : Here is the so-called Turbulette project folder, it will contain applications and project-level configuration files \ud83d\udcc1 alembic : Contains the Alembic scripts used when generating/applying DB migrations \ud83d\udcc4 env.py \ud83d\udcc4 script.py.mako \ud83d\udcc4 .env : The actual project settings live here \ud83d\udcc4 app.py : Your API entrypoint, it contains the ASGI app \ud83d\udcc4 settings.py : Will load settings from .env file Question Why have both .env and settings.py ? You don't have to . You can also put all your settings in settings.py . But Turbulette encourage you to follow the twelve-factor methodology , that recommend to separate settings from code because config varies substantially across deploys, code does not . This way, you can untrack .env from version control and only keep tracking settings.py , which will load settings from .env using Starlette's Config object. 2: Create the first app Now it's time to create a Turbulette application! Run this command under the project directory ( eshop ) : turb app --name account Info You need to run turb app under the project dir because the CLI needs to access the almebic.ini file to create the initial database migration. You should see your new app under the project folder : . \u2514\u2500\u2500 \ud83d\udcc1 eshop ... | \u2514\u2500\u2500 \ud83d\udcc1 account \u251c\u2500\u2500 \ud83d\udcc1 graphql \u251c\u2500\u2500 \ud83d\udcc1 migrations \u2502 \u2514\u2500\u2500 \ud83d\udcc4 20200926_1508_auto_ef7704f9741f_initial.py \u251c\u2500\u2500 \ud83d\udcc1 resolvers \u2514\u2500\u2500 \ud83d\udcc4 models.py Details : \ud83d\udcc1 graphql : All the GraphQL schema will live here \ud83d\udcc1 migrations : Will contain database migrations generated by Alembic \ud83d\udcc1 resolvers : Python package where you will write resolvers binded to the schema \ud83d\udcc4 models.py : Will hold GINO models for this app Question What is this \"initial\" python file under \ud83d\udcc1 migrations ? We won't cover database connection in this quickstart, but note that it's the initial database migration for the account app that creates its dedicated Alembic branch, needed to generate/apply per-app migrations. Before writing some code, the only thing to do is make Turbulette aware of our lovely account app. To do this, open \ud83d\udcc4 eshop/settings.py and add \"eshop.account\" to INSTALLED_APPS , so the application is registered and can be picked up by Turbulette at startup : # List installed Turbulette apps that defines some GraphQL schema INSTALLED_APPS = [ \"eshop.account\" ] 3: GraphQL schema Now that we have our project scaffold, we can start writing actual schema/code. Create a schema.gql file in the \ud83d\udcc1 graphql folder and add this base schema : extend type Mutation { registerCard(input: CreditCard!): SuccessOut! } input CreditCard { number: String! expiration: Date! name: String! } type SuccessOut { success: Boolean errors: [String] } Info Note that we extend the type Mutation because Turbulette already defines it. The same goes for Query type Notice that we used the Date scalar, it's one of the custom scalars provided by Turbulette. It parses string in the ISO8601 date format YYY-MM-DD. 4: Add pydantic model We want to validate our CreditCard input to ensure the user has entered a valid card number and date. Fortunately, Turbulette integrates with Pydantic , a data validation library that uses python type annotations, and offers a convenient way to generate a Pydantic model from a schema type. Create a new \ud83d\udcc4 pyd_models.py under \ud83d\udcc1 account : from turbulette.validation import GraphQLModel from pydantic import PaymentCardNumber class CreditCard ( GraphQLModel ): class GraphQL : gql_type = \"CreditCard\" fields = { \"number\" : PaymentCardNumber } What's happening here? The inherited GraphQLModel class is a pydantic model that knows about the GraphQL schema and can produce pydantic fields from a given GraphQL type. We specify the GraphQL type with the gql_type attribute; it's the only one required. But we also add a fields attribute to override the type of number field because it is string typed in our schema. If we don't add this, Turbulette will assume that number is a string and will annotate the number field as str . fields is a mapping between GraphQL field names and the type that will override the schema's one. Let's add another validation check: the expiration date. We want to ensure the user has entered a valid date (i.e., at least greater than now) : from datetime import datetime from pydantic import PaymentCardNumber from turbulette.validation import GraphQLModel , validator class CreditCard ( GraphQLModel ): class GraphQL : gql_type = \"CreditCard\" fields = { \"number\" : PaymentCardNumber } @validator ( \"expiration\" ) def check_expiration_date ( cls , value ): if value < datetime . now (): raise ValueError ( \"Expiration date is invalid\" ) return value Question Why don't we use the @validator from Pydantic? For those who have already used Pydantic, you probably know about the @validator decorator used to add custom validation rules on fields. But here, we use a @validator imported from turbulette.validation , why? They're almost identical. Turbulette's validator is just a shortcut to the Pydantic one with check_fields=False as a default, instead of True , because we use an inherited BaseModel . The above snippet would correctly work if we used Pydantic's validator and explicitly set @validator ( \"expiration\" , check_fields = False ) . 5: Add a resolver The last missing piece is the resolver for our user mutation, to make the API returning something when querying for it. The GraphQL part is handled by Ariadne , a schema-first GraphQL library that allows binding the logic to the schema with minimal code. As you may have guessed, we will create a new Python module in our \ud83d\udcc1 resolvers package. Let's call it \ud83d\udcc4 user.py : from turbulette import mutation from ..pyd_models import CreditCard @mutation . field ( \"registerCard\" ) async def register ( obj , info , valid_input , ** kwargs ): return { \"success\" : True } mutation is the base mutation type defined by Turbulette and is used to register all mutation resolvers (hence the use of extend type Mutation on the schema). For now, our resolver is very simple and doesn't do any data validation on inputs and doesn't handle errors. Turbulette has a @validate decorator that can be used to validate resolver input using a pydantic model (like the one defined in Step 4 ). Here's how to use it: from turbulette import mutation from ..pyd_models import CreditCard from turbulette.validation import validate @mutation . field ( \"registerCard\" ) @validate ( CreditCard ) async def register ( obj , info , valid_input , ** kwargs ): return { \"success\" : True } Note the new valid_input param. The @validate decorator produces it if the validation succeeds. But what happens otherwise? Normally, if the validation fails, pydantic will raise a ValidationError , but here the @validate decorator handles the exception and will add error messages returned by pydantic into a dedicated error field in the GraphQL response. 5: Run it Our user mutation is now binded to the schema, so let's test it. Start the server in the root directory (the one containing \ud83d\udcc1 eshop folder) : uvicorn eshop.app:app --port 8000 Now, go to http://localhost:8000/graphql , you will see the GraphQL Playground IDE. Finally, run the user mutation, for example : mutation card { registerCard( input: { number: \"4000000000000002\" expiration: \"2023-05-12\" name: \"John Doe\" } ) { success errors } } Should give you the following expected result : { \"data\" : { \"registerCard\" : { \"success\" : true , \"errors\" : null } } } Now, try entering a wrong date (before now ). You should see the validation error as expected: { \"data\" : { \"registerCard\" : { \"success\" : null , \"errors\" : [ \"expiration: Expiration date is invalid\" ] } } } Question How the error message end in the errors key? Indeed, we didn't specify anywhere that validation errors should be passed to the errors key in our SuccessOut GraphQL type. That is because Turbulette has a setting called ERROR_FIELD , which defaults to \"errors\" . This setting indicates the error field on the GraphLQ output type used by Turbulette when collecting query errors. It means that if you didn't specify ERROR_FIELD on the GraphQL type, you would get an exception telling you that the field is missing. It's the default (and recommended) way of handling errors in Turbulette. Still, as all happens in the @validate , you can always remove it and manually instantiate your Pydantic models in resolvers. Good job! \ud83d\udc4f That was a straightforward example, showing off a simple Turbulette API set up. To get the most of it, follow the User Guide.","title":"Turbulette"},{"location":"#requirements","text":"Python 3.6+ \ud83d\udc4d Turbulette makes use of great tools/frameworks and wouldn't exist without them : Ariadne - Schema-first GraphQL library Starlette - The little ASGI framework that shines GINO - Lightweight, async ORM Pydantic - Powerful data validation with type annotations Alembic - Lightweight database migration tool simple-settings - A generic settings system inspired by Django's one async-caches - Async caching library Click - A \"Command Line Interface Creation Kit\"","title":"Requirements"},{"location":"#installation","text":"pip install turbulette You will also need an ASGI server, such as uvicorn : pip install uvicorn","title":"Installation"},{"location":"#quick-start","text":"Here is a short example that demonstrates a minimal project setup. We will see how to scaffold a simple Turbulette project, create a Turbulette application, and write some GraphQL schema/resolver. It's advisable to start the project in a virtualenv to isolate your dependencies. Here we will be using poetry : poetry init Then, install Turbulette from PyPI : poetry add turbulette For the rest of the tutorial, we will assume that commands will be executed under the virtualenv. You can either prepend all commands with poetry run , or spawn a shell inside the virtualenv : poetry shell","title":"\ud83d\ude80 Quick Start"},{"location":"#1-create-a-project","text":"First, create a directory that will contain the whole project. Now, inside this folder, create your Turbulette project using the turb CLI : turb project eshop You should get with something like this : . \u2514\u2500\u2500 \ud83d\udcc1 eshop \u251c\u2500\u2500 \ud83d\udcc1 alembic \u2502 \u251c\u2500\u2500 \ud83d\udcc4 env.py \u2502 \u2514\u2500\u2500 \ud83d\udcc4 script.py.mako \u251c\u2500\u2500 \ud83d\udcc4 .env \u251c\u2500\u2500 \ud83d\udcc4 alembic.ini \u251c\u2500\u2500 \ud83d\udcc4 app.py \u2514\u2500\u2500 \ud83d\udcc4 settings.py Let's break down the structure : \ud83d\udcc1 eshop : Here is the so-called Turbulette project folder, it will contain applications and project-level configuration files \ud83d\udcc1 alembic : Contains the Alembic scripts used when generating/applying DB migrations \ud83d\udcc4 env.py \ud83d\udcc4 script.py.mako \ud83d\udcc4 .env : The actual project settings live here \ud83d\udcc4 app.py : Your API entrypoint, it contains the ASGI app \ud83d\udcc4 settings.py : Will load settings from .env file Question Why have both .env and settings.py ? You don't have to . You can also put all your settings in settings.py . But Turbulette encourage you to follow the twelve-factor methodology , that recommend to separate settings from code because config varies substantially across deploys, code does not . This way, you can untrack .env from version control and only keep tracking settings.py , which will load settings from .env using Starlette's Config object.","title":"1: Create a project"},{"location":"#2-create-the-first-app","text":"Now it's time to create a Turbulette application! Run this command under the project directory ( eshop ) : turb app --name account Info You need to run turb app under the project dir because the CLI needs to access the almebic.ini file to create the initial database migration. You should see your new app under the project folder : . \u2514\u2500\u2500 \ud83d\udcc1 eshop ... | \u2514\u2500\u2500 \ud83d\udcc1 account \u251c\u2500\u2500 \ud83d\udcc1 graphql \u251c\u2500\u2500 \ud83d\udcc1 migrations \u2502 \u2514\u2500\u2500 \ud83d\udcc4 20200926_1508_auto_ef7704f9741f_initial.py \u251c\u2500\u2500 \ud83d\udcc1 resolvers \u2514\u2500\u2500 \ud83d\udcc4 models.py Details : \ud83d\udcc1 graphql : All the GraphQL schema will live here \ud83d\udcc1 migrations : Will contain database migrations generated by Alembic \ud83d\udcc1 resolvers : Python package where you will write resolvers binded to the schema \ud83d\udcc4 models.py : Will hold GINO models for this app Question What is this \"initial\" python file under \ud83d\udcc1 migrations ? We won't cover database connection in this quickstart, but note that it's the initial database migration for the account app that creates its dedicated Alembic branch, needed to generate/apply per-app migrations. Before writing some code, the only thing to do is make Turbulette aware of our lovely account app. To do this, open \ud83d\udcc4 eshop/settings.py and add \"eshop.account\" to INSTALLED_APPS , so the application is registered and can be picked up by Turbulette at startup : # List installed Turbulette apps that defines some GraphQL schema INSTALLED_APPS = [ \"eshop.account\" ]","title":"2: Create the first app"},{"location":"#3-graphql-schema","text":"Now that we have our project scaffold, we can start writing actual schema/code. Create a schema.gql file in the \ud83d\udcc1 graphql folder and add this base schema : extend type Mutation { registerCard(input: CreditCard!): SuccessOut! } input CreditCard { number: String! expiration: Date! name: String! } type SuccessOut { success: Boolean errors: [String] } Info Note that we extend the type Mutation because Turbulette already defines it. The same goes for Query type Notice that we used the Date scalar, it's one of the custom scalars provided by Turbulette. It parses string in the ISO8601 date format YYY-MM-DD.","title":"3: GraphQL schema"},{"location":"#4-add-pydantic-model","text":"We want to validate our CreditCard input to ensure the user has entered a valid card number and date. Fortunately, Turbulette integrates with Pydantic , a data validation library that uses python type annotations, and offers a convenient way to generate a Pydantic model from a schema type. Create a new \ud83d\udcc4 pyd_models.py under \ud83d\udcc1 account : from turbulette.validation import GraphQLModel from pydantic import PaymentCardNumber class CreditCard ( GraphQLModel ): class GraphQL : gql_type = \"CreditCard\" fields = { \"number\" : PaymentCardNumber } What's happening here? The inherited GraphQLModel class is a pydantic model that knows about the GraphQL schema and can produce pydantic fields from a given GraphQL type. We specify the GraphQL type with the gql_type attribute; it's the only one required. But we also add a fields attribute to override the type of number field because it is string typed in our schema. If we don't add this, Turbulette will assume that number is a string and will annotate the number field as str . fields is a mapping between GraphQL field names and the type that will override the schema's one. Let's add another validation check: the expiration date. We want to ensure the user has entered a valid date (i.e., at least greater than now) : from datetime import datetime from pydantic import PaymentCardNumber from turbulette.validation import GraphQLModel , validator class CreditCard ( GraphQLModel ): class GraphQL : gql_type = \"CreditCard\" fields = { \"number\" : PaymentCardNumber } @validator ( \"expiration\" ) def check_expiration_date ( cls , value ): if value < datetime . now (): raise ValueError ( \"Expiration date is invalid\" ) return value Question Why don't we use the @validator from Pydantic? For those who have already used Pydantic, you probably know about the @validator decorator used to add custom validation rules on fields. But here, we use a @validator imported from turbulette.validation , why? They're almost identical. Turbulette's validator is just a shortcut to the Pydantic one with check_fields=False as a default, instead of True , because we use an inherited BaseModel . The above snippet would correctly work if we used Pydantic's validator and explicitly set @validator ( \"expiration\" , check_fields = False ) .","title":"4: Add pydantic model"},{"location":"#5-add-a-resolver","text":"The last missing piece is the resolver for our user mutation, to make the API returning something when querying for it. The GraphQL part is handled by Ariadne , a schema-first GraphQL library that allows binding the logic to the schema with minimal code. As you may have guessed, we will create a new Python module in our \ud83d\udcc1 resolvers package. Let's call it \ud83d\udcc4 user.py : from turbulette import mutation from ..pyd_models import CreditCard @mutation . field ( \"registerCard\" ) async def register ( obj , info , valid_input , ** kwargs ): return { \"success\" : True } mutation is the base mutation type defined by Turbulette and is used to register all mutation resolvers (hence the use of extend type Mutation on the schema). For now, our resolver is very simple and doesn't do any data validation on inputs and doesn't handle errors. Turbulette has a @validate decorator that can be used to validate resolver input using a pydantic model (like the one defined in Step 4 ). Here's how to use it: from turbulette import mutation from ..pyd_models import CreditCard from turbulette.validation import validate @mutation . field ( \"registerCard\" ) @validate ( CreditCard ) async def register ( obj , info , valid_input , ** kwargs ): return { \"success\" : True } Note the new valid_input param. The @validate decorator produces it if the validation succeeds. But what happens otherwise? Normally, if the validation fails, pydantic will raise a ValidationError , but here the @validate decorator handles the exception and will add error messages returned by pydantic into a dedicated error field in the GraphQL response.","title":"5: Add a resolver"},{"location":"#5-run-it","text":"Our user mutation is now binded to the schema, so let's test it. Start the server in the root directory (the one containing \ud83d\udcc1 eshop folder) : uvicorn eshop.app:app --port 8000 Now, go to http://localhost:8000/graphql , you will see the GraphQL Playground IDE. Finally, run the user mutation, for example : mutation card { registerCard( input: { number: \"4000000000000002\" expiration: \"2023-05-12\" name: \"John Doe\" } ) { success errors } } Should give you the following expected result : { \"data\" : { \"registerCard\" : { \"success\" : true , \"errors\" : null } } } Now, try entering a wrong date (before now ). You should see the validation error as expected: { \"data\" : { \"registerCard\" : { \"success\" : null , \"errors\" : [ \"expiration: Expiration date is invalid\" ] } } } Question How the error message end in the errors key? Indeed, we didn't specify anywhere that validation errors should be passed to the errors key in our SuccessOut GraphQL type. That is because Turbulette has a setting called ERROR_FIELD , which defaults to \"errors\" . This setting indicates the error field on the GraphLQ output type used by Turbulette when collecting query errors. It means that if you didn't specify ERROR_FIELD on the GraphQL type, you would get an exception telling you that the field is missing. It's the default (and recommended) way of handling errors in Turbulette. Still, as all happens in the @validate , you can always remove it and manually instantiate your Pydantic models in resolvers. Good job! \ud83d\udc4f That was a straightforward example, showing off a simple Turbulette API set up. To get the most of it, follow the User Guide.","title":"5: Run it"},{"location":"changelogs/","text":"0.4.0 (2020-10-24) Features Add subscription type and websocket route 0.3.1 Fixes Fix upgrade and makerevision CLI commands 0.3.0 Features Add Date scalar Add parser for the DateTime scalar Add include , exclude and fields settings when generating Pydantic models Make error field configurable in settings Fixes Fix .env path in settings.py generared by turb project Fix error when declaring validators on generated Pydantic models Changes The GraphQL config for GraphQLModel now must be declared in GraphQL inner class Rename @scope decorator to @policy Raise SchemaError if @policy is used on a non-nullable field Docs Improve Quick Start Internal Update dev dependencies Make the project structure less nested Remove camel_to_snake util and use convert_camel_case_to_snake from Ariadne instead 0.2.0 Features Generate Pydantic models from schema Policy based access control (PBAC) Add fresh token Add Turbulette CLI turb Add CRUD role methods on auth user model Add async-caches Add csrf middleware Add ariadne extensions through settings Add set_password() to AbtractUser Allow to start a project with no database connection Fixes Fix error when no routes was defined More consistent error codes Add mypy and black checks Docs Add quickstart documentation CI Move from Travis CI to Github Action Add pre-commit hooks Add mypy and black formatting checks in test workflow","title":"Release Notes"},{"location":"changelogs/#040-2020-10-24","text":"","title":"0.4.0 (2020-10-24)"},{"location":"changelogs/#features","text":"Add subscription type and websocket route","title":"Features"},{"location":"changelogs/#031","text":"","title":"0.3.1"},{"location":"changelogs/#fixes","text":"Fix upgrade and makerevision CLI commands","title":"Fixes"},{"location":"changelogs/#030","text":"","title":"0.3.0"},{"location":"changelogs/#features_1","text":"Add Date scalar Add parser for the DateTime scalar Add include , exclude and fields settings when generating Pydantic models Make error field configurable in settings","title":"Features"},{"location":"changelogs/#fixes_1","text":"Fix .env path in settings.py generared by turb project Fix error when declaring validators on generated Pydantic models","title":"Fixes"},{"location":"changelogs/#changes","text":"The GraphQL config for GraphQLModel now must be declared in GraphQL inner class Rename @scope decorator to @policy Raise SchemaError if @policy is used on a non-nullable field","title":"Changes"},{"location":"changelogs/#docs","text":"Improve Quick Start","title":"Docs"},{"location":"changelogs/#internal","text":"Update dev dependencies Make the project structure less nested Remove camel_to_snake util and use convert_camel_case_to_snake from Ariadne instead","title":"Internal"},{"location":"changelogs/#020","text":"","title":"0.2.0"},{"location":"changelogs/#features_2","text":"Generate Pydantic models from schema Policy based access control (PBAC) Add fresh token Add Turbulette CLI turb Add CRUD role methods on auth user model Add async-caches Add csrf middleware Add ariadne extensions through settings Add set_password() to AbtractUser Allow to start a project with no database connection","title":"Features"},{"location":"changelogs/#fixes_2","text":"Fix error when no routes was defined More consistent error codes Add mypy and black checks","title":"Fixes"},{"location":"changelogs/#docs_1","text":"Add quickstart documentation","title":"Docs"},{"location":"changelogs/#ci","text":"Move from Travis CI to Github Action Add pre-commit hooks Add mypy and black formatting checks in test workflow","title":"CI"},{"location":"faq/","text":"Isn't the project structure similar to Django's one? If you already used Django before, you probably noticed similarities with the project structure, as Turbulette is strongly inspired by the modular design of Django apps and the default project skeleton. The idea is to give the developers a default way of doing things while keeping the flexibility to write more complex projects. For instance, if your resolvers have to be available under the \ud83d\udcc1 resolvers folder, It's just a Python package at the end. You are free to move them elsewhere and to import them all inside \ud83d\udcc1 resolvers .","title":"FAQ"},{"location":"faq/#isnt-the-project-structure-similar-to-djangos-one","text":"If you already used Django before, you probably noticed similarities with the project structure, as Turbulette is strongly inspired by the modular design of Django apps and the default project skeleton. The idea is to give the developers a default way of doing things while keeping the flexibility to write more complex projects. For instance, if your resolvers have to be available under the \ud83d\udcc1 resolvers folder, It's just a Python package at the end. You are free to move them elsewhere and to import them all inside \ud83d\udcc1 resolvers .","title":"Isn't the project structure similar to Django's one?"},{"location":"user-guide/","text":"WIP","title":"User Guide"}]}